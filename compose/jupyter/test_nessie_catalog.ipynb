{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Nessie Catalog\n",
        "\n",
        "This notebook tests if the Nessie catalog is properly configured and accessible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing basic imports...\n",
            "✅ SparkSession imported\n",
            "✅ Basic imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Test basic imports\n",
        "print(\"Testing basic imports...\")\n",
        "try:\n",
        "    from pyspark.sql import SparkSession\n",
        "    print(\"✅ SparkSession imported\")\n",
        "    print(\"✅ Basic imports successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Import error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ AWS environment variables set for MinIO access\n"
          ]
        }
      ],
      "source": [
        "# Set AWS environment variables for MinIO access\n",
        "import os\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = 'minio'\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = 'minio12345'\n",
        "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
        "os.environ['AWS_ENDPOINT_URL'] = 'http://minio:9000'\n",
        "os.environ['AWS_ENDPOINT_URL_S3'] = 'http://minio:9000'\n",
        "print(\"✅ AWS environment variables set for MinIO access\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Spark session...\n",
            "✅ Spark session initialized successfully!\n",
            "Spark version: 3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Initialize Spark session with Iceberg and Nessie support\n",
        "from pyspark.sql import SparkSession\n",
        "print(\"Initializing Spark session...\")\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NessieCatalogTest\") \\\n",
        "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,org.projectnessie.spark.extensions.NessieSparkSessionExtensions\") \\\n",
        "    .config(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
        "    .config(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\") \\\n",
        "    .config(\"spark.sql.catalog.nessie.uri\", \"http://nessie:19120/api/v2\") \\\n",
        "    .config(\"spark.sql.catalog.nessie.ref\", \"main\") \\\n",
        "    .config(\"spark.sql.catalog.nessie.warehouse\", \"s3a://warehouse/\") \\\n",
        "    .config(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
        "    .config(\"spark.sql.catalog.nessie.s3.endpoint\", \"http://minio:9000\") \\\n",
        "    .config(\"spark.sql.catalog.nessie.s3.path-style-access\", \"true\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio12345\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
        "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"✅ Spark session initialized successfully!\")\n",
        "print(f\"Spark version: {spark.version}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available catalogs:\n",
            "+-------------+\n",
            "|      catalog|\n",
            "+-------------+\n",
            "|spark_catalog|\n",
            "+-------------+\n",
            "\n",
            "\n",
            "Testing Nessie catalog access:\n",
            "❌ Nessie catalog error: An error occurred while calling o65.sql.\n",
            ": org.projectnessie.client.http.NessieApiCompatibilityException: API version mismatch, check URI prefix (expected: 1, actual: 2)\n",
            "\tat org.projectnessie.client.http.NessieApiCompatibilityFilter.check(NessieApiCompatibilityFilter.java:78)\n",
            "\tat org.projectnessie.client.http.NessieApiCompatibilityFilter.filter(NessieApiCompatibilityFilter.java:43)\n",
            "\tat org.projectnessie.client.http.impl.BaseHttpRequest.lambda$prepareRequest$0(BaseHttpRequest.java:68)\n",
            "\tat java.base/java.util.Collections$SingletonList.forEach(Collections.java:4966)\n",
            "\tat org.projectnessie.client.http.impl.BaseHttpRequest.prepareRequest(BaseHttpRequest.java:68)\n",
            "\tat org.projectnessie.client.http.impl.jdk11.JavaRequest.executeRequest(JavaRequest.java:95)\n",
            "\tat org.projectnessie.client.http.HttpRequest.get(HttpRequest.java:80)\n",
            "\tat org.projectnessie.client.rest.v1.RestV1TreeClient.getReferenceByName(RestV1TreeClient.java:83)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "\tat org.projectnessie.client.rest.v1.RestV1Client$ExceptionRewriter.invoke(RestV1Client.java:78)\n",
            "\tat jdk.proxy3/jdk.proxy3.$Proxy37.getReferenceByName(Unknown Source)\n",
            "\tat org.projectnessie.client.rest.v1.HttpGetReference.get(HttpGetReference.java:34)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.loadReference(NessieIcebergClient.java:114)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.lambda$new$0(NessieIcebergClient.java:81)\n",
            "\tat org.apache.iceberg.relocated.com.google.common.base.Suppliers$NonSerializableMemoizingSupplier.get(Suppliers.java:181)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.getRef(NessieIcebergClient.java:89)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.withReference(NessieIcebergClient.java:501)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.listNamespaces(NessieIcebergClient.java:207)\n",
            "\tat org.apache.iceberg.nessie.NessieCatalog.listNamespaces(NessieCatalog.java:296)\n",
            "\tat org.apache.iceberg.catalog.SupportsNamespaces.listNamespaces(SupportsNamespaces.java:74)\n",
            "\tat org.apache.iceberg.spark.SparkCatalog.listNamespaces(SparkCatalog.java:423)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.ShowNamespacesExec.run(ShowNamespacesExec.scala:42)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
            "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
            "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
            "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
            "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
            "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test catalog availability\n",
        "print(\"Available catalogs:\")\n",
        "spark.sql(\"SHOW CATALOGS\").show()\n",
        "\n",
        "print(\"\\nTesting Nessie catalog access:\")\n",
        "try:\n",
        "    spark.sql(\"SHOW DATABASES IN nessie\").show()\n",
        "    print(\"✅ Nessie catalog is accessible!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Nessie catalog error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing database creation:\n",
            "❌ Database creation error: An error occurred while calling o65.sql.\n",
            ": org.projectnessie.client.rest.NessieServiceException: Not Found (HTTP/404): \n",
            "\n",
            "Additionally, the client-side exception below was caught while decoding the HTTP response:\n",
            "org.apache.iceberg.shaded.com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `org.projectnessie.error.ImmutableNessieError` from [Unavailable value] (token `JsonToken.NOT_AVAILABLE`)\n",
            " at [Source: UNKNOWN; byte offset: #UNKNOWN]\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1752)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1526)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1473)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:224)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:187)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2079)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1229)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1247)\n",
            "\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader.treeToValue(ObjectReader.java:2024)\n",
            "\tat org.projectnessie.client.rest.ResponseCheckFilter.decodeErrorObject(ResponseCheckFilter.java:121)\n",
            "\tat org.projectnessie.client.rest.ResponseCheckFilter.checkResponse(ResponseCheckFilter.java:65)\n",
            "\tat org.projectnessie.client.rest.NessieHttpResponseFilter.filter(NessieHttpResponseFilter.java:29)\n",
            "\tat org.projectnessie.client.http.impl.jdk11.JavaRequest.lambda$executeRequest$1(JavaRequest.java:140)\n",
            "\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n",
            "\tat java.base/java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1092)\n",
            "\tat org.projectnessie.client.http.impl.jdk11.JavaRequest.executeRequest(JavaRequest.java:140)\n",
            "\tat org.projectnessie.client.http.HttpRequest.get(HttpRequest.java:80)\n",
            "\tat org.projectnessie.client.rest.v1.RestV1TreeClient.getReferenceByName(RestV1TreeClient.java:83)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "\tat org.projectnessie.client.rest.v1.RestV1Client$ExceptionRewriter.invoke(RestV1Client.java:78)\n",
            "\tat jdk.proxy3/jdk.proxy3.$Proxy37.getReferenceByName(Unknown Source)\n",
            "\tat org.projectnessie.client.rest.v1.HttpGetReference.get(HttpGetReference.java:34)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.loadReference(NessieIcebergClient.java:114)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.lambda$new$0(NessieIcebergClient.java:81)\n",
            "\tat org.apache.iceberg.relocated.com.google.common.base.Suppliers$NonSerializableMemoizingSupplier.get(Suppliers.java:181)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.getRef(NessieIcebergClient.java:89)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.withReference(NessieIcebergClient.java:501)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.loadNamespaceMetadata(NessieIcebergClient.java:253)\n",
            "\tat org.apache.iceberg.nessie.NessieCatalog.loadNamespaceMetadata(NessieCatalog.java:309)\n",
            "\tat org.apache.iceberg.spark.SparkCatalog.loadNamespaceMetadata(SparkCatalog.java:451)\n",
            "\tat org.apache.spark.sql.connector.catalog.SupportsNamespaces.namespaceExists(SupportsNamespaces.java:98)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.CreateNamespaceExec.run(CreateNamespaceExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
            "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
            "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
            "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
            "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
            "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
            "\n",
            "\tat org.projectnessie.client.rest.ResponseCheckFilter.checkResponse(ResponseCheckFilter.java:94)\n",
            "\tat org.projectnessie.client.rest.NessieHttpResponseFilter.filter(NessieHttpResponseFilter.java:29)\n",
            "\tat org.projectnessie.client.http.impl.jdk11.JavaRequest.lambda$executeRequest$1(JavaRequest.java:140)\n",
            "\tat java.base/java.util.ArrayList.forEach(ArrayList.java:1511)\n",
            "\tat java.base/java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1092)\n",
            "\tat org.projectnessie.client.http.impl.jdk11.JavaRequest.executeRequest(JavaRequest.java:140)\n",
            "\tat org.projectnessie.client.http.HttpRequest.get(HttpRequest.java:80)\n",
            "\tat org.projectnessie.client.rest.v1.RestV1TreeClient.getReferenceByName(RestV1TreeClient.java:83)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "\tat org.projectnessie.client.rest.v1.RestV1Client$ExceptionRewriter.invoke(RestV1Client.java:78)\n",
            "\tat jdk.proxy3/jdk.proxy3.$Proxy37.getReferenceByName(Unknown Source)\n",
            "\tat org.projectnessie.client.rest.v1.HttpGetReference.get(HttpGetReference.java:34)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.loadReference(NessieIcebergClient.java:114)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.lambda$new$0(NessieIcebergClient.java:81)\n",
            "\tat org.apache.iceberg.relocated.com.google.common.base.Suppliers$NonSerializableMemoizingSupplier.get(Suppliers.java:181)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.getRef(NessieIcebergClient.java:89)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.withReference(NessieIcebergClient.java:501)\n",
            "\tat org.apache.iceberg.nessie.NessieIcebergClient.loadNamespaceMetadata(NessieIcebergClient.java:253)\n",
            "\tat org.apache.iceberg.nessie.NessieCatalog.loadNamespaceMetadata(NessieCatalog.java:309)\n",
            "\tat org.apache.iceberg.spark.SparkCatalog.loadNamespaceMetadata(SparkCatalog.java:451)\n",
            "\tat org.apache.spark.sql.connector.catalog.SupportsNamespaces.namespaceExists(SupportsNamespaces.java:98)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.CreateNamespaceExec.run(CreateNamespaceExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
            "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n",
            "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n",
            "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n",
            "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)\n",
            "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n",
            "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n",
            "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
            "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n",
            "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
            "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
            "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
            "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
            "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
            "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
            "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
            "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
            "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
            "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
            "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
            "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
            "\tSuppressed: org.apache.iceberg.shaded.com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `org.projectnessie.error.ImmutableNessieError` from [Unavailable value] (token `JsonToken.NOT_AVAILABLE`)\n",
            " at [Source: UNKNOWN; byte offset: #UNKNOWN]\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1752)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1526)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1473)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:224)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:187)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2079)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1229)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1247)\n",
            "\t\tat org.apache.iceberg.shaded.com.fasterxml.jackson.databind.ObjectReader.treeToValue(ObjectReader.java:2024)\n",
            "\t\tat org.projectnessie.client.rest.ResponseCheckFilter.decodeErrorObject(ResponseCheckFilter.java:121)\n",
            "\t\tat org.projectnessie.client.rest.ResponseCheckFilter.checkResponse(ResponseCheckFilter.java:65)\n",
            "\t\t... 67 more\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test creating a simple database\n",
        "print(\"Testing database creation:\")\n",
        "try:\n",
        "    spark.sql(\"CREATE DATABASE IF NOT EXISTS nessie.test_db\")\n",
        "    print(\"✅ Database created successfully!\")\n",
        "    \n",
        "    # Show databases again\n",
        "    print(\"\\nAvailable databases in nessie catalog:\")\n",
        "    spark.sql(\"SHOW DATABASES IN nessie\").show()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Database creation error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Spark session stopped\n"
          ]
        }
      ],
      "source": [
        "# Clean up\n",
        "spark.stop()\n",
        "print(\"✅ Spark session stopped\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
