services:
  dummy-wait:
    image: alpine
    depends_on:
      trino:
        condition: service_healthy
      jupyter:
        condition: service_healthy
      # trino-coordinator:
      #   condition: service_healthy

  minio:
    image: quay.io/minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio12345}
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # Web console
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/ready"]
      interval: 5s
      timeout: 3s
      retries: 30
    volumes:
      - minio-data:/data
    networks: [lake]

  # one-shot init job: create the 'warehouse' bucket in MinIO
  minio-init:
    image: quay.io/minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set local http://minio:9000 $${MINIO_ROOT_USER} $${MINIO_ROOT_PASSWORD} &&
      mc mb -p local/warehouse || true &&
      mc policy set none local/warehouse || true
      "
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio12345}
    networks: [lake]
    restart: "no"

  # backing database for Nessie (persistent)
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: nessie
      POSTGRES_PASSWORD: nessie
      POSTGRES_DB: nessie
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nessie -d nessie"]
      interval: 5s
      timeout: 5s
      retries: 20
    volumes:
      - pg-data:/var/lib/postgresql/data
    networks: [lake]

  nessie:
    image: ghcr.io/projectnessie/nessie:0.104.3-java
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      QUARKUS_HTTP_PORT: 19120
      QUARKUS_HTTP_HOST: 0.0.0.0
      QUARKUS_LOG_LEVEL: INFO
      QUARKUS_LOG_CATEGORY__ORG_PROJECTNESSIE: DEBUG
      QUARKUS_HIBERNATE_ORM_DATABASE_GENERATION: update
      QUARKUS_DATASOURCE_POSTGRESQL_JDBC_URL: jdbc:postgresql://postgres:5432/nessie
      QUARKUS_DATASOURCE_POSTGRESQL_USERNAME: nessie
      QUARKUS_DATASOURCE_POSTGRESQL_PASSWORD: nessie
      NESSIE_VERSION_STORE_TYPE: JDBC
      NESSIE_VERSION_STORE_PERSIST_JDBC_DATASOURCE: postgresql
    ports:
      - "19120:19120"   # Nessie API
    healthcheck:
      # Ready when API responds
      test: ["CMD", "curl", "-f", "http://localhost:19120/api/v2/config"]
      interval: 5s
      timeout: 3s
      retries: 60
    networks: [lake]

  # Single-node Trino (original)
  trino:
    image: trinodb/trino:latest
    depends_on:
      nessie:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    environment:
      # Only for logging/identification
      JAVA_TOOL_OPTIONS: "-Duser.timezone=UTC"
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio12345}
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8080/v1/info | grep -q '\"starting\"[[:space:]]*:[[:space:]]*false'"]
      interval: 5s
      timeout: 3s
      retries: 60
    volumes:
      - ./trino/catalog:/etc/trino/catalog:ro
      # 2gb
      # - ./trino/config2g.properties:/etc/trino/config.properties:ro
      # - ./trino/jvm2g.config:/etc/trino/jvm.config:ro
      # 4gb
      # - ./trino/config4g.properties:/etc/trino/config.properties:ro
      # - ./trino/jvm4g.config:/etc/trino/jvm.config:ro
    networks: [lake]

  # # two-node Trino cluster
  # trino-coordinator:
  #   image: trinodb/trino:latest
  #   depends_on:
  #     nessie:
  #       condition: service_healthy
  #     minio-init:
  #       condition: service_completed_successfully
  #   environment:
  #     JAVA_TOOL_OPTIONS: "-Duser.timezone=UTC"
  #     MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
  #     MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio12345}
  #   ports:
  #     - "8081:8080"  # Coordinator on different port
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -fsS http://localhost:8080/v1/info | grep -q '\"starting\"[[:space:]]*:[[:space:]]*false'"]
  #     interval: 5s
  #     timeout: 3s
  #     retries: 60
  #   volumes:
  #     - ./trino/catalog:/etc/trino/catalog:ro
  #     - ./trino/cluster-coordinator.properties:/etc/trino/config.properties:ro
  #   networks: [lake]

  # trino-worker-1:
  #   image: trinodb/trino:latest
  #   depends_on:
  #     trino-coordinator:
  #       condition: service_healthy
  #   environment:
  #     JAVA_TOOL_OPTIONS: "-Duser.timezone=UTC"
  #     MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
  #     MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio12345}
  #   volumes:
  #     - ./trino/catalog:/etc/trino/catalog:ro
  #     - ./trino/cluster-worker.properties:/etc/trino/config.properties:ro
  #   networks: [lake]

  # trino-worker-2:
  #   image: trinodb/trino:latest
  #   depends_on:
  #     trino-coordinator:
  #       condition: service_healthy
  #   environment:
  #     JAVA_TOOL_OPTIONS: "-Duser.timezone=UTC"
  #     MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
  #     MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio12345}
  #   volumes:
  #     - ./trino/catalog:/etc/trino/catalog:ro
  #     - ./trino/cluster-worker.properties:/etc/trino/config.properties:ro
  #   networks: [lake]

  jupyter:
    image: jupyter/pyspark-notebook:x86_64-spark-3.5.0
    container_name: jupyter-spark
    depends_on:
      nessie:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully
    environment:
      # AWS credentials for MinIO access
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minio}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minio12345}
      AWS_DEFAULT_REGION: us-east-1
      # MinIO endpoint configuration
      AWS_ENDPOINT_URL: http://minio:9000
      AWS_ENDPOINT_URL_S3: http://minio:9000
      # Spark configuration for Iceberg
      SPARK_CONF_DIR: /opt/spark/conf
      PYSPARK_PYTHON: python3
      PYSPARK_DRIVER_PYTHON: python3
    ports:
      - "8888:8888"   # Jupyter notebook port
    volumes:
      - ./jupyter:/home/jovyan/work
      - ./jupyter/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
    networks: [lake]
    command: >
      bash -c "
      pip install -r /home/jovyan/work/requirements.txt &&
      wget -O /opt/conda/lib/python3.11/site-packages/pyspark/jars/iceberg-spark-runtime-3.5_2.12-1.4.2.jar https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.5_2.12/1.4.2/iceberg-spark-runtime-3.5_2.12-1.4.2.jar &&
      wget -O /opt/conda/lib/python3.11/site-packages/pyspark/jars/iceberg-nessie-1.4.2.jar https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-nessie/1.4.2/iceberg-nessie-1.4.2.jar &&
      wget -O /opt/conda/lib/python3.11/site-packages/pyspark/jars/iceberg-aws-bundle-1.4.2.jar https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-aws-bundle/1.4.2/iceberg-aws-bundle-1.4.2.jar &&
      wget -O /opt/conda/lib/python3.11/site-packages/pyspark/jars/nessie-spark-extensions-3.5_2.12-0.104.5.jar https://repo1.maven.org/maven2/org/projectnessie/nessie-integrations/nessie-spark-extensions-3.5_2.12/0.104.5/nessie-spark-extensions-3.5_2.12-0.104.5.jar &&
      start-notebook.sh
      --NotebookApp.token=''
      --NotebookApp.password=''
      --NotebookApp.allow_origin='*'
      --NotebookApp.ip='0.0.0.0'
      --NotebookApp.open_browser=False
      "

networks:
  lake: {}

volumes:
  minio-data: {}
  pg-data: {}
